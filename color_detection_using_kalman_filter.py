# -*- coding: utf-8 -*-
"""Color detection using kalman filter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ePt_bVfy66TXCg-dEEWislePn9_nxkvE
"""

import cv2
import numpy as np
import json
from google.colab.patches import cv2_imshow

# Initialize Kalman Filter parameters
dt = 1.0  # Time step
KF = cv2.KalmanFilter(4, 2)  # 4 states (x, y, dx, dy), 2 measurements (x, y)
KF.transitionMatrix = np.array([[1, 0, dt, 0],
                                [0, 1, 0, dt],
                                [0, 0, 1, 0],
                                [0, 0, 0, 1]], np.float32)
KF.measurementMatrix = np.array([[1, 0, 0, 0],
                                 [0, 1, 0, 0]], np.float32)

# Color detection parameters
lower_color = np.array([0, 100, 100])  # Lower color range (HSV format)
upper_color = np.array([10, 255, 255])  # Upper color range (HSV format)

# Initialize JSON data
tracked_objects = []

# Open video capture
cap = cv2.VideoCapture('/content/flowers_yellow_blossom_windy_nature_434.mp4')

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Convert frame to HSV color space for color detection
    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Perform color detection
    mask = cv2.inRange(hsv_frame, lower_color, upper_color)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Track the largest contour (assumed to be the object of interest)
    if contours:
        contour = max(contours, key=cv2.contourArea)
        (x, y, w, h) = cv2.boundingRect(contour)
        center = (x + w // 2, y + h // 2)

        # Predict the next state using Kalman Filter
        prediction = KF.predict()

        # Update the Kalman Filter with the detected position
        measurement = np.array([center[0], center[1]], np.float32)
        KF.correct(measurement)

        # Store the tracked object's information
        tracked_object = {
            'position': (int(prediction[0]), int(prediction[1])),
            'color': frame[center[1], center[0]].tolist(),
        }
        tracked_objects.append(tracked_object)

    # Display the tracked object on the frame
    if len(tracked_objects) > 0:
        cv2.circle(frame, tracked_objects[-1]['position'], 5, (0, 255, 0), -1)

    # Display the frame
    cv2_imshow(frame)

    # Check for 'q' key press to exit
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()

# Save tracked object data to a JSON file
with open('tracked_objects.json', 'w') as json_file:
    json.dump(tracked_objects, json_file, indent=4)